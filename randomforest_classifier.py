# -*- coding: utf-8 -*-
"""rANDOMfOREST cLASSIFIER.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Gc7SNRBmaU1n2ifrFPzrSHRxWxPOOIHX
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

df = pd.read_csv("Fraud_check.csv")

print("ðŸ“‹ Dataset Preview:")
display(df.head())

print("\nðŸ“Š Dataset Information:")
print(df.info())

print("\nðŸ”¢ Shape of the dataset:", df.shape)
print("\nâœ… Missing Values Check:")
print(df.isnull().sum())

print("\nðŸ“ˆ Basic Statistics:")
display(df.describe())

df["Taxable.Income_Status"] = df["Taxable.Income"].apply(lambda x: "Risky" if x <= 30000 else "Good")

print("\nðŸŽ¯ Target Variable Distribution:")
print(df["Taxable.Income_Status"].value_counts())

plt.figure(figsize=(6,4))
sns.countplot(x="Taxable.Income_Status", data=df, palette="Set2")
plt.title("Distribution of Risky vs Good Taxpayers")
plt.show()

df = df.drop(columns=["Taxable.Income"])

# Encode categorical columns
label_enc = LabelEncoder()
for col in ["Undergrad", "Marital.Status", "Urban", "Taxable.Income_Status"]:
    df[col] = label_enc.fit_transform(df[col])

print("\nðŸ”  Encoded Columns Sample:")
display(df.head())

X = df.drop(columns=["Taxable.Income_Status"])
y = df["Taxable.Income_Status"]

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42, stratify=y
)
print("\nâœ… Data Split Done:")
print("Training Samples:", X_train.shape[0])
print("Testing Samples:", X_test.shape[0])

rf = RandomForestClassifier(
    n_estimators=200,
    criterion="entropy",
    random_state=42,
    max_depth=None,
    min_samples_split=2,
    min_samples_leaf=1
)
rf.fit(X_train, y_train)

y_pred = rf.predict(X_test)

print("\nðŸŽ¯ Model Performance:")
print("Accuracy:", round(accuracy_score(y_test, y_pred)*100, 2), "%")
print("\nðŸ“Š Classification Report:")
print(classification_report(y_test, y_pred))

# Confusion Matrix
plt.figure(figsize=(5,4))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='coolwarm')
plt.title("Confusion Matrix - Random Forest")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

feature_imp = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)
plt.figure(figsize=(8,5))
sns.barplot(x=feature_imp, y=feature_imp.index, palette="viridis")
plt.title("Feature Importance - Random Forest")
plt.xlabel("Importance Score")
plt.ylabel("Features")
plt.show()

print("\nðŸ“ˆ Feature Importance Table:")
display(feature_imp)

print("\nâœ… Random Forest Fraud Detection Project Completed Successfully!")